# ğŸš€ IngenierÃ­a de Datos â€“ AceleraTI 2025

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![AWS](https://img.shields.io/badge/AWS-Data%20Engineering-orange.svg)](https://aws.amazon.com/)
[![Terraform](https://img.shields.io/badge/IaC-Terraform-623CE4.svg)](https://www.terraform.io/)
[![Airflow](https://img.shields.io/badge/Orchestration-Apache%20Airflow-lightblue.svg)](https://airflow.apache.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Repositorio oficial del curso **IngenierÃ­a de Datos â€“ AceleraTI 2025**, diseÃ±ado para formar profesionales capaces de diseÃ±ar, automatizar y escalar soluciones modernas de datos en la nube con foco en pipelines distribuidos, modelado, gobernanza y operaciones de datos.  
ğŸ“„ [Programa oficial del curso (PDF)](https://acelerati.co/hubfs/TRI%20-%202025/Programa/AceleraTI%20-%20Programa%20Ingenier%C3%ADa%20de%20datos.pdf?hsLang=es-co)

---

## ğŸ¯ Objetivo

Desarrollar las habilidades tÃ©cnicas y prÃ¡cticas para construir **arquitecturas de datos escalables**, seguras y confiables en la nube, comprendiendo el ciclo completo de un pipeline moderno: desde la ingesta hasta la visualizaciÃ³n y automatizaciÃ³n en producciÃ³n.


---

## ğŸ§© Estructura del curso

DuraciÃ³n: **160 horas (4.5 meses)**  
Modalidad: **Virtual en vivo**  
MetodologÃ­a: **TeorÃ­a + prÃ¡ctica + proyecto transversal**

### MÃ³dulos principales
1. **Fundamentos de ingenierÃ­a de datos y cloud**
2. **Bases de datos relacionales y NoSQL**
3. **Arquitectura de datos y Data Lakes**
4. **Procesamiento distribuido con Apache Spark**
5. **Streaming y datos en tiempo real**
6. **DataOps y automatizaciÃ³n con Airflow / GitHub Actions**
7. **Modelado de datos y bodegas analÃ­ticas**
8. **Infraestructura y DevOps con AWS y Terraform**
9. **Gobernanza, calidad y validaciÃ³n (Great Expectations)**
10. **Proyecto final integrador**

---

## ğŸ§° Stack tecnolÃ³gico

| CategorÃ­a | TecnologÃ­as |
|------------|--------------|
| **Lenguajes** | Python, SQL, Bash |
| **Bases de Datos** | PostgreSQL, MongoDB, DynamoDB |
| **Procesamiento** | Apache Spark (PySpark), Kafka, Kinesis |
| **OrquestaciÃ³n** | Apache Airflow, Prefect, GitHub Actions |
| **Infraestructura Cloud** | AWS (S3, Glue, Redshift, Lambda, Lake Formation, DataZone) |
| **Infraestructura como cÃ³digo (IaC)** | Terraform |
| **VisualizaciÃ³n** | Amazon QuickSight |
| **Data Quality / Tests** | Great Expectations |

---

## ğŸ“ Estructura del repositorio

```bash
ingenieria-de-datos-acelerati/
â”‚
â”œâ”€â”€ modulo-01_fundamentos/
â”œâ”€â”€ modulo-02_bases_datos/
â”œâ”€â”€ modulo-03_data_lake/
â”œâ”€â”€ modulo-04_spark/
â”œâ”€â”€ modulo-05_streaming/
â”œâ”€â”€ modulo-06_dataops/
â”œâ”€â”€ modulo-07_modelado/
â”œâ”€â”€ modulo-08_infraestructura/
â”œâ”€â”€ modulo-09_gobernanza/
â”œâ”€â”€ modulo-10_proyecto_final/
â”‚
â”œâ”€â”€ docs/                 # DocumentaciÃ³n del curso y guÃ­as adicionales
â”œâ”€â”€ notebooks/            # Ejemplos prÃ¡cticos y laboratorios
â”œâ”€â”€ terraform/            # Plantillas IaC para AWS
â”œâ”€â”€ airflow_dags/         # Flujos de orquestaciÃ³n (ETL/ELT)
â””â”€â”€ README.md
```

## ğŸ’» CÃ³mo usar este repositorio

1. Clona el proyecto
```bash
git clone https://github.com/tu-usuario/ingenieria-de-datos.git
cd ingenieria-de-datos-
```
2. Crea y activa un entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```
3. Instala dependencias
```bash
pip install -r requirements.txt
```
4. Ejecuta ejemplos o notebooks
Cada mÃ³dulo tiene su propio README.md con pasos especÃ­ficos, datasets de ejemplo y scripts asociados.

---

## ğŸ§ª Buenas prÃ¡cticas
- Usa ramas tipo feature/tu-nombre o moduleX/experiment.

- Realiza commits descriptivos y claros.

- Usa black o ruff para mantener el formato del cÃ³digo.

- AÃ±ade docstrings y logging a tus scripts.

- Implementa tests unitarios donde aplique (pytest recomendado).

---

## ğŸ“˜ Proyecto final
- El curso culmina con un proyecto integral donde se construye una arquitectura de datos moderna completa:

- Ingesta batch y streaming.

- Limpieza, transformaciÃ³n y modelado.

- ValidaciÃ³n con Great Expectations.

- OrquestaciÃ³n y despliegue automatizado.

- ExposiciÃ³n de insights mediante QuickSight o dashboards BI.

---

## ğŸ“„ Licencia
Este repositorio se distribuye bajo licencia MIT.
Consulta el archivo LICENSE para mÃ¡s informaciÃ³n.

---






